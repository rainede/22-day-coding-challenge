{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": " CLASSIFICATION_EN_TREC.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/raineydavid/22-day-coding-challenge/blob/master/python/CLASSIFICATION_TREC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vas1PNJwZp2U"
      },
      "source": [
        "\n",
        "\n",
        "![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://githubtocolab.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/streamlit_notebooks/CLASSIFICATION_EN_TREC.ipynb)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E2lonApkZwJP"
      },
      "source": [
        "# **Classify text according to TREC classes**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kMURhBz4ZwM6"
      },
      "source": [
        "## 1. Colab Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sIJfXkK54WFk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72433760-91c5-4d6d-9073-291a4b7817c8"
      },
      "source": [
        "!wget http://setup.johnsnowlabs.com/colab.sh -O - | bash\n",
        "# !bash colab.sh\n",
        "# -p is for pyspark\n",
        "# -s is for spark-nlp\n",
        "# !bash colab.sh -p 3.1.1 -s 3.0.1\n",
        "# by default they are set to the latest"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-06-27 01:14:36--  http://setup.johnsnowlabs.com/colab.sh\n",
            "Resolving setup.johnsnowlabs.com (setup.johnsnowlabs.com)... 51.158.130.125\n",
            "Connecting to setup.johnsnowlabs.com (setup.johnsnowlabs.com)|51.158.130.125|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp/master/scripts/colab_setup.sh [following]\n",
            "--2021-06-27 01:14:36--  https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp/master/scripts/colab_setup.sh\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1608 (1.6K) [text/plain]\n",
            "Saving to: ‘STDOUT’\n",
            "\n",
            "setup Colab for PySpark 3.0.3 and Spark NLP 3.1.1\n",
            "-                   100%[===================>]   1.57K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-06-27 01:14:36 (41.0 MB/s) - written to stdout [1608/1608]\n",
            "\n",
            "Ign:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:2 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease\n",
            "Ign:3 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Get:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release [697 B]\n",
            "Hit:5 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Get:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release.gpg [836 B]\n",
            "Get:7 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Get:8 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n",
            "Hit:9 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Get:11 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Ign:12 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages\n",
            "Get:12 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages [599 kB]\n",
            "Hit:13 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Get:14 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Get:15 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease [15.9 kB]\n",
            "Get:16 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2,220 kB]\n",
            "Get:17 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease [21.3 kB]\n",
            "Get:18 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,418 kB]\n",
            "Get:19 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [473 kB]\n",
            "Get:20 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [1,774 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,188 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [2,653 kB]\n",
            "Get:23 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [505 kB]\n",
            "Get:24 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [907 kB]\n",
            "Get:25 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic/main amd64 Packages [40.9 kB]\n",
            "Get:26 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic/main amd64 Packages [41.5 kB]\n",
            "Fetched 13.1 MB in 5s (2,693 kB/s)\n",
            "Reading package lists... Done\n",
            "\u001b[K     |████████████████████████████████| 209.1MB 78kB/s \n",
            "\u001b[K     |████████████████████████████████| 51kB 7.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 204kB 53.1MB/s \n",
            "\u001b[?25h  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rpXDCBhNoApC",
        "outputId": "f75c11e7-a662-492f-eaae-39f4eea39bf3"
      },
      "source": [
        "!wget http://setup.johnsnowlabs.com/colab.sh "
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-06-27 01:16:19--  http://setup.johnsnowlabs.com/colab.sh\n",
            "Resolving setup.johnsnowlabs.com (setup.johnsnowlabs.com)... 51.158.130.125\n",
            "Connecting to setup.johnsnowlabs.com (setup.johnsnowlabs.com)|51.158.130.125|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp/master/scripts/colab_setup.sh [following]\n",
            "--2021-06-27 01:16:20--  https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp/master/scripts/colab_setup.sh\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1608 (1.6K) [text/plain]\n",
            "Saving to: ‘colab.sh’\n",
            "\n",
            "colab.sh            100%[===================>]   1.57K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-06-27 01:16:20 (27.0 MB/s) - ‘colab.sh’ saved [1608/1608]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QevdHttso2pt",
        "outputId": "18712923-12e9-4a78-fc2d-31ae7c627895"
      },
      "source": [
        "!cat colab.sh"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "#!/bin/bash\n",
            "\n",
            "#default values for pyspark, spark-nlp, and SPARK_HOME\n",
            "SPARKNLP=\"3.1.1\"\n",
            "PYSPARK=\"3.0.3\"\n",
            "SPARKHOME=\"/content/spark-3.1.2-bin-hadoop2.7\"\n",
            "\n",
            "while getopts s:p: option\n",
            "do\n",
            " case \"${option}\"\n",
            " in\n",
            " s) SPARKNLP=${OPTARG};;\n",
            " p) PYSPARK=${OPTARG};;\n",
            " esac\n",
            "done\n",
            "\n",
            "echo \"setup Colab for PySpark $PYSPARK and Spark NLP $SPARKNLP\"\n",
            "apt-get update\n",
            "apt-get purge -y openjdk-11* -qq > /dev/null && sudo apt-get autoremove -y -qq > /dev/null\n",
            "apt-get install -y openjdk-8-jdk-headless -qq > /dev/null\n",
            "\n",
            "if [[ \"$PYSPARK\" == \"3.1\"* ]]; then\n",
            "  wget -q \"https://downloads.apache.org/spark/spark-3.1.2/spark-3.1.2-bin-hadoop2.7.tgz\" > /dev/null\n",
            "  tar -xvf spark-3.1.2-bin-hadoop2.7.tgz > /dev/null\n",
            "  SPARKHOME=\"/content/spark-3.1.2-bin-hadoop2.7\"\n",
            "elif [[ \"$PYSPARK\" == \"3.0\"* ]]; then\n",
            "  wget -q \"https://downloads.apache.org/spark/spark-3.0.3/spark-3.0.3-bin-hadoop2.7.tgz\" > /dev/null\n",
            "  tar -xvf spark-3.0.3-bin-hadoop2.7.tgz > /dev/null\n",
            "  SPARKHOME=\"/content/spark-3.0.3-bin-hadoop2.7\"\n",
            "elif [[ \"$PYSPARK\" == \"2\"* ]]; then\n",
            "  wget -q \"https://downloads.apache.org/spark/spark-2.4.8/spark-2.4.8-bin-hadoop2.7.tgz\" > /dev/null\n",
            "  tar -xvf spark-2.4.8-bin-hadoop2.8.tgz > /dev/null\n",
            "  SPARKHOME=\"/content/spark-2.4.8-bin-hadoop2.7\"\n",
            "else\n",
            "  wget -q \"https://downloads.apache.org/spark/spark-3.1.2/spark-3.1.2-bin-hadoop2.7.tgz\" > /dev/null\n",
            "  tar -xvf spark-3.1.2-bin-hadoop2.7.tgz > /dev/null\n",
            "  SPARKHOME=\"/content/spark-3.1.2-bin-hadoop2.7\"\n",
            "fi\n",
            "\n",
            "export SPARK_HOME=$SPARKHOME\n",
            "export JAVA_HOME=\"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
            "\n",
            "# Install pyspark spark-nlp\n",
            "! pip install --upgrade -q pyspark==$PYSPARK spark-nlp==$SPARKNLP findspark\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v29AZ9XO5AhU"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.sql import SparkSession\n",
        "import pyspark.sql.functions as F\n",
        "from sparknlp.annotator import *\n",
        "from sparknlp.base import *\n",
        "import sparknlp\n",
        "from sparknlp.pretrained import PretrainedPipeline"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PKf4YBDBZ9x7"
      },
      "source": [
        "## 2. Start Spark Session"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sI-CZ9PO5GW9"
      },
      "source": [
        "spark = sparknlp.start()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bXA24WIYaACJ"
      },
      "source": [
        "## 3. Select the DL model and re-run all the cells below\n",
        "\n",
        "The classes in TREC-6 are\n",
        "\n",
        "ABBR - Abbreviation\n",
        "\n",
        "DESC - Description and abstract concepts\n",
        "\n",
        "ENTY - Entities\n",
        "\n",
        "HUM - Human beings\n",
        "\n",
        "LOC - Locations\n",
        "\n",
        "NYM - Numeric values\n",
        "\n",
        "the classes in TREC-50 can be found here https://cogcomp.seas.upenn.edu/Data/QA/QC/definition.html.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y6s6ljDsH9ZK"
      },
      "source": [
        "### Select Model\n",
        "#model_name = 'classifierdl_use_trec6'\n",
        "model_name = 'classifierdl_use_trec50'"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m_-O5I9BaF08"
      },
      "source": [
        "## 4. Some sample examples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WGFzBK1EX8wm"
      },
      "source": [
        "\n",
        "text_list = [\n",
        "    \"What effect does pollution have on the Chesapeake Bay oysters?\",\n",
        "    \"What financial relationships exist between Google and its advertisers?\",\n",
        "    \"What financial relationships exist between the Chinese government and the Cuban government?\",\n",
        "    \"What was the number of member nations of the U.N. in 2000?\",\n",
        "    \"Who is the Secretary-General for political affairs?\",\n",
        "    \"When did the construction of stone circles begin in the UK?\",\n",
        "    \"In what country is the WTO headquartered?\",\n",
        "    \"What animal was the first mammal successfully cloned from adult cells?\",\n",
        "    \"What other prince showed his paintings in a two-prince exhibition with Prince Charles in London?\",\n",
        "    \"Is there evidence to support the involvement of Garry Kasparov in politics?\",\n",
        "  ]"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ULKvemZpaNal"
      },
      "source": [
        "## 5. Define Spark NLP pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K2CS_jdi5Phc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "246762b2-085d-41d9-dc65-da25ff8fadc3"
      },
      "source": [
        "documentAssembler = DocumentAssembler()\\\n",
        "    .setInputCol(\"text\")\\\n",
        "    .setOutputCol(\"document\")\n",
        "\n",
        "use = UniversalSentenceEncoder.pretrained(lang=\"en\") \\\n",
        " .setInputCols([\"document\"])\\\n",
        " .setOutputCol(\"sentence_embeddings\")\n",
        "\n",
        "\n",
        "document_classifier = ClassifierDLModel.pretrained(model_name, 'en') \\\n",
        "          .setInputCols([\"document\", \"sentence_embeddings\"]) \\\n",
        "          .setOutputCol(\"class\")\n",
        "\n",
        "nlpPipeline = Pipeline(stages=[\n",
        " documentAssembler, \n",
        " use,\n",
        " document_classifier\n",
        " ])\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tfhub_use download started this may take some time.\n",
            "Approximate size to download 923.7 MB\n",
            "[OK!]\n",
            "classifierdl_use_trec50 download started this may take some time.\n",
            "Approximate size to download 21.2 MB\n",
            "[OK!]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hZtgPiQPafLR"
      },
      "source": [
        "## 6. Run the pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lr3DMHgd5Pk8"
      },
      "source": [
        "empty_df = spark.createDataFrame([['']]).toDF(\"text\")\n",
        "\n",
        "pipelineModel = nlpPipeline.fit(empty_df)\n",
        "df = spark.createDataFrame(pd.DataFrame({\"text\":text_list}))\n",
        "result = pipelineModel.transform(df)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GM8GfPB5aSCu"
      },
      "source": [
        "## 7. Visualize results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P84W1Z4uPI_b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07453036-9651-499f-fd36-d9cdbd0d0b56"
      },
      "source": [
        "result.select(F.explode(F.arrays_zip('document.result', 'class.result')).alias(\"cols\")) \\\n",
        ".select(F.expr(\"cols['0']\").alias(\"document\"),\n",
        "        F.expr(\"cols['1']\").alias(\"class\")).show(truncate=False)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------------------------------------------------------------------------------------------------+------------+\n",
            "|document                                                                                        |class       |\n",
            "+------------------------------------------------------------------------------------------------+------------+\n",
            "|What effect does pollution have on the Chesapeake Bay oysters?                                  | DESC_desc  |\n",
            "|What financial relationships exist between Google and its advertisers?                          | DESC_desc  |\n",
            "|What financial relationships exist between the Chinese government and the Cuban government?     | DESC_desc  |\n",
            "|What was the number of member nations of the U.N. in 2000?                                      | NUM_count  |\n",
            "|Who is the Secretary-General for political affairs?                                             | HUM_ind    |\n",
            "|When did the construction of stone circles begin in the UK?                                     | LOC_other  |\n",
            "|In what country is the WTO headquartered?                                                       | LOC_other  |\n",
            "|What animal was the first mammal successfully cloned from adult cells?                          | HUM_ind    |\n",
            "|What other prince showed his paintings in a two-prince exhibition with Prince Charles in London?| HUM_ind    |\n",
            "|Is there evidence to support the involvement of Garry Kasparov in politics?                     | DESC_reason|\n",
            "+------------------------------------------------------------------------------------------------+------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}